# custom_date_digester.py
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ¬´–®–∞–≥-4¬ª: —Å–æ–±–∏—Ä–∞–µ—Ç —Ç–µ–º—ã-—á–∞—Ç–∞ + –ø–æ—Å—Ç—ã –∫–∞–Ω–∞–ª–∞ –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥,
# –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –∏—Ö –≤ ‚â§10 ¬´—Å—é–∂–µ—Ç–æ–≤¬ª, –¥–µ–ª–∞–µ—Ç –æ–¥–∏–Ω –≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç-–¥–∞–π–¥–∂–µ—Å—Ç
# –∏ –∫–ª–∞–¥—ë—Ç –≤ //tmp/ia-nartov/hackathon/custom_date_digest  (upsert)

from __future__ import annotations
import datetime as dt, json, os, re
from typing import Any, Dict, List

import pandas as pd
from dateutil import tz

from . import tg_etl
from . import eliza_client


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ YT —Ç–∞–±–ª–∏—Ü—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ROOT            = os.getenv("YT_ROOT", "//tmp/ia-nartov/hackathon")
TBL_TOPICS      = f"{ROOT}/topic_analysis"
TBL_POSTS       = f"{ROOT}/post_summaries"
TBL_CHATS       = f"{ROOT}/tg_chats"
TBL_OUT         = f"{ROOT}/custom_date_digest"

SCHEMA_OUT = [
    {"name": "digest_id",   "type": "string", "sort_order": "ascending"},  # channel_id+start+end
    {"name": "channel_id",  "type": "int64"},
    {"name": "start_date",  "type": "string"},
    {"name": "end_date",    "type": "string"},
    {"name": "digest_text", "type": "string"},
]

MSK = tz.gettz("Europe/Moscow")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PROMPTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
PERIOD_PROMPT = """
–¢—ã ‚Äî –≤–µ–¥—É—â–∏–π —Ä–µ–¥–∞–∫—Ç–æ—Ä –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö –¥–∞–π–¥–∂–µ—Å—Ç–æ–≤.
–ó–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ —Ç—ã –ø–æ–ª—É—á–∞–µ—à—å **–µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤**, –≥–¥–µ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç ‚Äî
–ª–∏–±–æ –ø–µ—Ä–µ—Å–∫–∞–∑ —Ç–µ–º—ã-–æ–±—Å—É–∂–¥–µ–Ω–∏—è –∏–∑ —á–∞—Ç–∞ (`type = "topic"`),
–ª–∏–±–æ —Å–∂–∞—Ç—ã–π –ø–æ—Å—Ç –∫–∞–Ω–∞–ª–∞ (`type = "post"`).
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ ¬´—Å—é–∂–µ—Ç—ã¬ª –∏ –≤—ã–¥–∞—Ç—å
**–¥–æ 10** –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã—Ö —Å—é–∂–µ—Ç–Ω—ã—Ö –ª–∏–Ω–∏–π –ø–µ—Ä–∏–æ–¥–∞.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üõà –í–•–û–î
–ü–µ—Ä–∏–æ–¥: {start_date} ‚Üí {end_date}
–ö–∞–Ω–∞–ª: {channel_name} ‚Äî {channel_description}

–î–∞–Ω–Ω—ã–µ:
json
{items_json}


‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìã –ó–ê–î–ê–ß–ê
‚Ä¢ –°–≥—Ä—É–ø–ø–∏—Ä—É–π —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Å—é–∂–µ—Ç, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç –æ–¥–Ω—É —Ç–µ–º—É
(–ø–æ—Ö–æ–∂–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–±—â–∞—è —Ü–µ–ª—å, –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –∫–ª—é—á–µ–≤—ã–µ —É—á–∞—Å—Ç–Ω–∏–∫–∏, –∏–ª–∏ –ª–æ–≥–∏—á–µ—Å–∫–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è).
‚Ä¢ –í–ê–ñ–ù–û: –£—á–∏—Ç—ã–≤–∞–π, —á—Ç–æ status –∏ conclusions –æ–¥–Ω–æ–≥–æ –¥–Ω—è –º–æ–≥—É—Ç –ø–µ—Ä–µ—Ç–µ–∫–∞—Ç—å –≤ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å, –µ—Å–ª–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è.
‚Ä¢ –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—é–∂–µ—Ç–∞ —Å—Ñ–æ—Ä–º–∏—Ä—É–π –∏—Ç–æ–≥ —Å —É—á—ë—Ç–æ–º –¥–∏–Ω–∞–º–∏–∫–∏ –ø–æ –¥–Ω—è–º –∏ —ç–≤–æ–ª—é—Ü–∏–∏ –æ–±—Å—É–∂–¥–µ–Ω–∏—è.
‚Ä¢ –û—Ç—Å–æ—Ä—Ç–∏—Ä—É–π —Å—é–∂–µ—Ç—ã –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –∏ –≤—ã–±–µ—Ä–∏ –º–∞–∫—Å–∏–º—É–º 10.

‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üì§ –í–´–•–û–î ‚Äî JSON-–º–∞—Å—Å–∏–≤ (1‚Äì10 –æ–±—ä–µ–∫—Ç–æ–≤) –≤ —Ñ–æ—Ä–º–∞—Ç–µ:

jsonc
[
  {{
    "rank": 1,
    "title": "‚Ä¶",
    "days_covered": ["YYYY-MM-DD", ‚Ä¶],
    "summary": "‚Ä¶",
    "evolution": ["‚Ä¶", "‚Ä¶"],
    "final_status": "—Ä–µ—à–µ–Ω–æ|—Å–ø–æ—Ä|–æ—Ç–ª–æ–∂–∏–ª–∏|–Ω–µ—è—Å–Ω–æ|null",
    "key_participants": [
      {{"name":"‚Ä¶","role":"‚Ä¶"}}
    ],
    "resume": "–û–¥–Ω–∞ –∏—Ç–æ–≥–æ–≤–∞—è —Ñ—Ä–∞–∑–∞"
  }},
  /* rank 2 ‚Ä¶ */
]


‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ñ–∞–∫—Ç–æ–≤.
‚Ä¢ –ü–æ–ª—è title/summary/evolution/resume ‚Äî —Ä—É—Å—Å–∫–∏–π, –Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ-–¥–µ–ª–æ–≤–æ–π, –±–µ–∑ markdown.
‚Ä¢ –ò—Ç–æ–≥ ‚Äî –≤–∞–ª–∏–¥–Ω—ã–π JSON, ‚â§ 600 —Ç–æ–∫–µ–Ω–æ–≤.
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
–°—Ñ–æ—Ä–º–∏—Ä—É–π –º–∞—Å—Å–∏–≤ —Ä–æ–≤–Ω–æ –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤–æ–∫—Ä—É–≥).
"""

POST_PROMPT = """
–°–¥–µ–ª–∞–π –æ–¥–∏–Ω –≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç-–¥–∞–π–¥–∂–µ—Å—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞:

–§–æ—Ä–º–∞—Ç:

1. –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∏–¥–∞ ¬´–î–∞–π–¥–∂–µ—Å—Ç:  {start} ‚Äì {end}¬ª
2. –ó–∞—Ç–µ–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å—é–∂–µ—Ç–∞ bullet-–ø—É–Ω–∫—Ç ¬´‚Ä¢ [–¥–Ω–∏] title: summary¬ª
   –≥–¥–µ [–¥–Ω–∏] - —ç—Ç–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–Ω–µ–π, –∫–æ–≥–¥–∞ –æ–±—Å—É–∂–¥–∞–ª–∞—Å—å —Ç–µ–º–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [21-23])

–ü—Ä–∞–≤–∏–ª–∞:
‚Ä¢ –ë–æ–ª—å—à–µ –Ω–∏—á–µ–≥–æ: –Ω–∏–∫–∞–∫–æ–≥–æ markdown, —ç–º–æ–¥–∑–∏, –ø–æ–¥–ø–∏—Å–µ–π.
‚Ä¢ –ü—É–Ω–∫—Ç—ã –∏–¥—É—Ç –ø–æ —Ä–∞–Ω–≥—É —Å—é–∂–µ—Ç–æ–≤.
‚Ä¢ –î–æ 10 –ø—É–Ω–∫—Ç–æ–≤.
‚Ä¢ –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–Ω–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—É–Ω–∫—Ç–∞

–î–∞–Ω–Ω—ã–µ —Å—é–∂–µ—Ç–æ–≤ (JSON):

json
{stories_json}


‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
–í–µ—Ä–Ω–∏ –û–î–ò–ù —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫-–ø–æ—Å—Ç –±–µ–∑ –æ–±—Ä–∞–º–ª–µ–Ω–∏—è.
"""

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _channel_row(channel_id: int) -> pd.Series:
    return tg_etl.query_yql(
    f"""SELECT chat, description
    FROM hahn.`{TBL_CHATS}`
    WHERE chat_id = {channel_id}
    LIMIT 1;"""
    ).iloc[0]

def _load_items(channel_id: int,
    start: dt.date,
    end: dt.date) -> list[dict]:
    """–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ items –∑–∞ –ø–µ—Ä–∏–æ–¥"""
    topics = tg_etl.query_yql(
    f"""
    SELECT
    "topic" AS type, date, summary, status, conclusions
    FROM hahn.`{TBL_TOPICS}`
    WHERE channel_id = {channel_id}
    AND date BETWEEN "{start}" AND "{end}"
    """
    )
    
    items = []
    if not topics.empty:
        items.extend(topics.to_dict("records"))
    return items

def _prompt_period(start: dt.date,
    end: dt.date,
    channel: pd.Series,
    items: list[dict]) -> List[Dict[str, str]]:
    
    txt = PERIOD_PROMPT.format(
    start_date=start,
    end_date=end,
    channel_name=channel["chat"],
    channel_description=channel["description"],
    items_json=json.dumps({"items": items}, ensure_ascii=False, indent=2)
    )
    return [{"role": "user", "content": txt}]

def _parse_stories(raw: str) -> list[dict]:
    try:
        data = json.loads(raw)
    except json.JSONDecodeError:
        cleaned = re.sub(r"`json|`", "", raw, flags=re.I).strip()
        data = json.loads(cleaned)
        
    if not isinstance(data, list) or len(data) == 0:
        raise ValueError("LLM output must be non-empty JSON array")
    return data[:10]

def _prompt_post(start: dt.date, end: dt.date,
    stories: list[dict]) -> List[Dict[str, str]]:
    txt = POST_PROMPT.format(
    start=start.strftime("%d %b"),
    end=end.strftime("%d %b"),
    stories_json=json.dumps(stories, ensure_ascii=False, indent=2)
    )
    return [{"role": "user", "content": txt}]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ main entry ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def run_custom_date_digester(
    start_date: dt.date,
    end_date: dt.date,
    channel_id: int,
    *,
    model: str = "yandex",
    verify: bool | str = True,
    ) -> None:
    """
    –î–µ–ª–∞–µ—Ç –¥–∞–π–¥–∂–µ—Å—Ç –∑–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ (—Ç–µ–∫—Å—Ç-–ø–æ—Å—Ç) –∏ –∫–ª–∞–¥—ë—Ç –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –≤ custom_date_digest.
    """
    channel = _channel_row(channel_id)
    items   = _load_items(channel_id, start_date, end_date)
    
    
    if not items:
        print("‚è≠  –ù–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∑–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥")
        return
    
    # step-1: LLM –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Å—é–∂–µ—Ç—ã
    rsp1 = eliza_client.eliza_chat(
        _prompt_period(start_date, end_date, channel, items),
        model=model,
        verify=verify
    )
    stories = _parse_stories(rsp1["response"]["Responses"][0]["Response"])

    # step-2: LLM —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ø–æ—Å—Ç
    rsp2 = eliza_client.eliza_chat(
        _prompt_post(start_date, end_date, stories),
        model=model,
        verify=verify
    )
    digest_text = rsp2["response"]["Responses"][0]["Response"].strip()
    
    # –ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
    print(f"\n{'='*60}")
    print(f"üìä –î–ê–ô–î–ñ–ï–°–¢ –ó–ê –ü–ï–†–ò–û–î {start_date} ‚Äì {end_date}")
    print(f"üì¢ –ö–∞–Ω–∞–ª: {channel['chat']}")
    print(f"{'='*60}")
    print(f"\n{digest_text}")
    print(f"\n{'='*60}")
    
    row = {
        "digest_id": f"{channel_id}_{start_date}_{end_date}",
        "channel_id": channel_id,
        "start_date": str(start_date),
        "end_date": str(end_date),
        "digest_text": digest_text
    }
    tg_etl.upsert_df_to_yt(pd.DataFrame([row]), TBL_OUT, SCHEMA_OUT)
    print(f"‚úÖ custom date digest {start_date}‚Äì{end_date} saved ‚Üí {TBL_OUT}")
